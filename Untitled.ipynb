{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45782bc-85c9-4df9-9c38-8c1b59b60841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Amazon Review Analysis and Prediction\n",
    "# This notebook performs data extraction, preprocessing, feature engineering, and modeling on Amazon review data.\n",
    "\n",
    "## **1. Import Libraries and Define Utility Functions**\n",
    "# Import essential libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Download NLTK resources if not already available\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6477faf2-6727-43e7-91b6-41407331aaf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Exception Class for Handling Errors\n",
    "class CustomException(Exception):\n",
    "    def __init__(self, message, original_exception):\n",
    "        super().__init__(message)\n",
    "        self.original_exception = original_exception\n",
    "\n",
    "# Class to Handle TF-IDF Vectorization in Pipelines\n",
    "class TfidfVectorizerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_features=100):\n",
    "        self.max_features = max_features\n",
    "        self.vectorizer = TfidfVectorizer(max_features=self.max_features)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.vectorizer.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50e18f7-4c9a-4c3d-a716-829040a4e0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flesch_kincaid(text):\n",
    "    \"\"\"Calculate Flesch-Kincaid readability score.\"\"\"\n",
    "    try:\n",
    "        words = word_tokenize(text)\n",
    "        sentences = len(re.split(r'[.!?]', text))\n",
    "        syllables = sum([len([s for s in word if s in 'aeiou']) for word in words])\n",
    "        if len(words) == 0 or sentences == 0:\n",
    "            return np.nan\n",
    "        return 206.835 - (1.015 * (len(words) / sentences)) - (84.6 * (syllables / len(words)))\n",
    "    except Exception as e:\n",
    "        raise CustomException(\"Error in flesch_kincaid calculation\", e)\n",
    "\n",
    "def pos_counts(text):\n",
    "    \"\"\"Calculate counts of nouns, verbs, and adjectives in text.\"\"\"\n",
    "    try:\n",
    "        words = word_tokenize(text)\n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "        pos_counts = {\"nouns\": 0, \"verbs\": 0, \"adjectives\": 0}\n",
    "        for _, tag in pos_tags:\n",
    "            if tag.startswith('N'):\n",
    "                pos_counts[\"nouns\"] += 1\n",
    "            elif tag.startswith('V'):\n",
    "                pos_counts[\"verbs\"] += 1\n",
    "            elif tag.startswith('J'):\n",
    "                pos_counts[\"adjectives\"] += 1\n",
    "        return pd.Series(pos_counts)\n",
    "    except Exception as e:\n",
    "        raise CustomException(\"Error calculating POS counts\", e)\n",
    "\n",
    "def add_feature_columns(df):\n",
    "    \"\"\"Adds various feature columns to the DataFrame based on text analysis.\"\"\"\n",
    "    try:\n",
    "        df['review_length'] = df['review_text'].apply(len)\n",
    "        df['review_word_count'] = df['review_text'].apply(lambda x: len(word_tokenize(x)))\n",
    "        df['review_sentiment'] = df['review_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "        df['review_subjectivity'] = df['review_text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "        df['flesch_kincaid'] = df['review_text'].apply(flesch_kincaid)\n",
    "\n",
    "        # Add keyword-based features\n",
    "        keywords = ['good', 'bad', 'recommend', 'disappoint', 'excellent']\n",
    "        for keyword in keywords:\n",
    "            df[f'keyword_{keyword}'] = df['review_text'].apply(lambda x: int(keyword in x.lower()))\n",
    "\n",
    "        # Calculate rating deviation\n",
    "        avg_rating = df['rating'].mean()\n",
    "        df['rating_deviation'] = df['rating'] - avg_rating\n",
    "        df['title_sentiment'] = df['title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "        df['title_length'] = df['title'].apply(len)\n",
    "\n",
    "        # Part of speech counts\n",
    "        pos_features = df['review_text'].apply(pos_counts)\n",
    "        df = pd.concat([df, pos_features], axis=1)\n",
    "\n",
    "        # Negation and pronoun counts\n",
    "        negations = [\"not\", \"no\", \"never\", \"none\"]\n",
    "        df['negation_count'] = df['review_text'].apply(lambda x: sum([x.lower().count(neg) for neg in negations]))\n",
    "\n",
    "        pronouns = [\"i\", \"we\", \"you\", \"he\", \"she\", \"they\"]\n",
    "        df['pronoun_count'] = df['review_text'].apply(lambda x: sum([x.lower().count(pronoun) for pronoun in pronouns]))\n",
    "        df['helpful_to_length_ratio'] = df['helpful_votes'] / (df['review_length'] + 1)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise CustomException(\"Error in add_feature_columns function\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d7667c-eda3-42bb-92e7-102f210e56be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_from_bigquery(query):\n",
    "    client = bigquery.Client()\n",
    "    try:\n",
    "        df = client.query(query).to_dataframe()\n",
    "        print(\"Data loaded from BigQuery successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise CustomException(\"Error loading data from BigQuery\", e)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocesses data for model training.\"\"\"\n",
    "    try:\n",
    "        df = add_feature_columns(df)\n",
    "        bins = [0, 1, 5, float(\"inf\")]\n",
    "        labels = [\"low\", \"medium\", \"high\"]\n",
    "        df['helpfulness_class'] = pd.cut(df['helpful_votes'], bins=bins, labels=labels)\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['helpfulness_class_encoded'] = label_encoder.fit_transform(df['helpfulness_class'])\n",
    "        \n",
    "        X = df.drop(columns=['helpful_votes', 'helpfulness_class', 'helpfulness_class_encoded'])\n",
    "        y = df['helpfulness_class_encoded']\n",
    "        \n",
    "        # Numerical and text transformations\n",
    "        numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        review_text_transformer = TfidfVectorizerTransformer(max_features=100)\n",
    "        title_transformer = TfidfVectorizerTransformer(max_features=100)\n",
    "        \n",
    "        # Concatenate transformations\n",
    "        X_num = numerical_transformer.fit_transform(X[numerical_cols])\n",
    "        X_review_text = review_text_transformer.fit_transform(X['review_text'])\n",
    "        X_title = title_transformer.fit_transform(X['title'])\n",
    "        \n",
    "        return np.hstack([X_num, X_review_text, X_title]), y\n",
    "    except Exception as e:\n",
    "        raise CustomException(\"Error in preprocess_data function\", e)\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Trains the model.\"\"\"\n",
    "    try:\n",
    "        model = Pipeline(steps=[\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        raise CustomException(\"Error training the model\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac6a61e-7121-4347-8b2b-794e91c915ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from BigQuery successfully.\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "Error in preprocess_data function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m, in \u001b[0;36madd_feature_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     59\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpronoun_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([x\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mcount(pronoun) \u001b[38;5;28;01mfor\u001b[39;00m pronoun \u001b[38;5;129;01min\u001b[39;00m pronouns]))\n\u001b[0;32m---> 60\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelpful_to_length_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhelpful_votes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6134\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 6135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:227\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m     left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:163\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 163\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43madd_feature_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     bins \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[5], line 64\u001b[0m, in \u001b[0;36madd_feature_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CustomException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in add_feature_columns function\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "\u001b[0;31mCustomException\u001b[0m: Error in add_feature_columns function",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM `airy-box-431604-j9.amazon_reviews.clean_data`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data_from_bigquery(query)\n\u001b[0;32m----> 3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(X_train, y_train)\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mhstack([X_num, X_review_text, X_title]), y\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CustomException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in preprocess_data function\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "\u001b[0;31mCustomException\u001b[0m: Error in preprocess_data function"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM `airy-box-431604-j9.amazon_reviews.clean_data`\"\n",
    "df = load_data_from_bigquery(query)\n",
    "X, y = preprocess_data(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = train_model(X_train, y_train)\n",
    "\n",
    "# Model evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Model accuracy:\", accuracy)\n",
    "print(\"Classification report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da9f8a-b09a-4215-a6ec-88b9e79a33ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
